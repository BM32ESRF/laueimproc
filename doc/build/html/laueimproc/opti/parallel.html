<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>laueimproc.opti.parallel API documentation</title>
<meta name="description" content="Manage the auto multithreading." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>laueimproc.opti.parallel</code></h1>
</header>
<section id="section-intro">
<p>Manage the auto multithreading.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python3

&#34;&#34;&#34;Manage the auto multithreading.&#34;&#34;&#34;

import functools
import hashlib
import logging
import pickle
import queue
import threading
import typing

import psutil

from laueimproc.opti.manager import DiagramManager
from laueimproc.opti.singleton import MetaSingleton


CPU_AVAILABLE = len(psutil.Process().cpu_affinity())  # more accurate than os.cpu_count()


class ThreadManager(threading.Thread, metaclass=MetaSingleton):
    &#34;&#34;&#34;Excecute several functions in parallel threads.&#34;&#34;&#34;

    def __init__(self):
        self.jobs = {}  # each signature, associate the thread
        self.lock = threading.Lock()
        self.submit_event = queue.Queue(maxsize=1)  # faor passive waiting base on event
        super().__init__(daemon=True)  # daemon has to be true to allow to exit python
        self.start()

    def run(self):
        &#34;&#34;&#34;Asynchrone control loop.&#34;&#34;&#34;
        while True:
            # starts waiting threads
            with self.lock:
                running = [job for job in self.jobs.values() if job.is_alive()]
                if nbr_to_append := max(0, 3*CPU_AVAILABLE//2-len(running)):
                    for job in self.jobs.values():
                        if not job._started.is_set():  # pylint: disable=W0212
                            job.start()
                            if (nbr_to_append := nbr_to_append-1) == 0:
                                break

            # transfere terminated result thread in cache
            with self.lock:
                finish = {
                    signature: job for signature, job in self.jobs.items()
                    if job._started.is_set() and not job.is_alive() # pylint: disable=W0212
                }
                for signature in finish:
                    del self.jobs[signature]
            for signature, job in finish.items():
                with job.diagram._cache_lock:  # pylint: disable=W0212
                    try:
                        job.diagram._cache[signature] = job.get()  # pylint: disable=W0212
                    except Exception as err:  # pylint: disable=W0718
                        logging.error(err)

            # wait to free up resources
            job = running.pop(0) if running else None
            if job is not None:
                job.join()  # passive waiting
            else:
                try:
                    self.submit_event.get(timeout=0.5)
                except queue.Empty:  # beter than a short time.sleep active waiting
                    pass

    def submit_job(self, meth, diagram, args, kwargs, signature):
        if not self.is_alive():
            raise RuntimeError(&#34;the thread manager is dead&#34;)
        with self.lock:
            if signature not in self.jobs:
                self.jobs[signature] = Calculator(meth, diagram, args, kwargs)
            job = self.jobs[signature]
        try:
            self.submit_event.put_nowait(None)  # just for trigger main thread
        except queue.Full:
            pass
        return job

    def pop(self, meth, diagram, args, kwargs, signature):
        job = self.submit_job(meth, diagram, args, kwargs, signature)
        with self.lock:
            if not job._started.is_set():
                job.start()
        # return job.get()  # unreferenced by `run` thread
        res = job.get()
        with self.lock:  # delete all references
            if signature in self.jobs:
                del self.jobs[signature]
        with diagram._cache_lock:
            if signature in diagram._cache:
                del diagram._cache[signature]
        return res


class Calculator(threading.Thread):
    def __init__(self, meth, diagram, args, kwargs):
        self.meth, self.diagram, self.args, self.kwargs = meth, diagram, args, kwargs
        self.result = self.exception = None
        super().__init__(daemon=True)

    def run(self):
        try:
            self.result = self.meth(self.diagram, *self.args, **self.kwargs)
        except Exception as err:
            self.exception = err

    def get(self):
        self.join()
        if self.exception is not None:
            raise self.exception
        return self.result


def auto_parallel(meth: typing.Callable) -&gt; typing.Callable:
    &#34;&#34;&#34;Decorator to auto multithread a Diagram method.&#34;&#34;&#34;
    assert callable(meth), meth.__class__.__name__
    @functools.wraps(meth)
    def multithreaded_meth(diagram, *args, parallel: bool = True, **kwargs):
        # case no threaded calculus
        assert isinstance(parallel, bool), parallel.__class__.__name__
        if not parallel or threading.current_thread().name != &#34;MainThread&#34;:
            return meth(diagram, *args, **kwargs)
        # case cached
        param_sig = hashlib.md5(pickle.dumps((args, kwargs)), usedforsecurity=False).hexdigest()
        signature = f&#34;thread: {diagram.state}.{meth.__name__}({param_sig})&#34;
        with diagram._cache_lock:  # pylint: disable=W0212
            if signature in diagram._cache:  # pylint: disable=W0212
                return diagram._cache.pop(signature)  # pylint: disable=W0212
        # case thread calculus
        thread_manager = ThreadManager()
        for next_diagram in DiagramManager().get_nexts_diagrams(diagram, 3*CPU_AVAILABLE):
            next_signature = (f&#34;thread: {next_diagram.state}.{meth.__name__}({param_sig})&#34;)
            with next_diagram._cache_lock:  # pylint: disable=W0212
                if next_signature not in next_diagram._cache:  # pylint: disable=W0212
                    thread_manager.submit_job(meth, next_diagram, args, kwargs, next_signature)
        return thread_manager.pop(meth, diagram, args, kwargs, signature)

    return multithreaded_meth</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="laueimproc.opti.parallel.auto_parallel"><code class="name flex">
<span>def <span class="ident">auto_parallel</span></span>(<span>meth: Callable) ‑> Callable</span>
</code></dt>
<dd>
<div class="desc"><p>Decorator to auto multithread a Diagram method.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def auto_parallel(meth: typing.Callable) -&gt; typing.Callable:
    &#34;&#34;&#34;Decorator to auto multithread a Diagram method.&#34;&#34;&#34;
    assert callable(meth), meth.__class__.__name__
    @functools.wraps(meth)
    def multithreaded_meth(diagram, *args, parallel: bool = True, **kwargs):
        # case no threaded calculus
        assert isinstance(parallel, bool), parallel.__class__.__name__
        if not parallel or threading.current_thread().name != &#34;MainThread&#34;:
            return meth(diagram, *args, **kwargs)
        # case cached
        param_sig = hashlib.md5(pickle.dumps((args, kwargs)), usedforsecurity=False).hexdigest()
        signature = f&#34;thread: {diagram.state}.{meth.__name__}({param_sig})&#34;
        with diagram._cache_lock:  # pylint: disable=W0212
            if signature in diagram._cache:  # pylint: disable=W0212
                return diagram._cache.pop(signature)  # pylint: disable=W0212
        # case thread calculus
        thread_manager = ThreadManager()
        for next_diagram in DiagramManager().get_nexts_diagrams(diagram, 3*CPU_AVAILABLE):
            next_signature = (f&#34;thread: {next_diagram.state}.{meth.__name__}({param_sig})&#34;)
            with next_diagram._cache_lock:  # pylint: disable=W0212
                if next_signature not in next_diagram._cache:  # pylint: disable=W0212
                    thread_manager.submit_job(meth, next_diagram, args, kwargs, next_signature)
        return thread_manager.pop(meth, diagram, args, kwargs, signature)

    return multithreaded_meth</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="laueimproc.opti.parallel.Calculator"><code class="flex name class">
<span>class <span class="ident">Calculator</span></span>
<span>(</span><span>meth, diagram, args, kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A class that represents a thread of control.</p>
<p>This class can be safely subclassed in a limited fashion. There are two ways
to specify the activity: by passing a callable object to the constructor, or
by overriding the run() method in a subclass.</p>
<p>This constructor should always be called with keyword arguments. Arguments are:</p>
<p><em>group</em> should be None; reserved for future extension when a ThreadGroup
class is implemented.</p>
<p><em>target</em> is the callable object to be invoked by the run()
method. Defaults to None, meaning nothing is called.</p>
<p><em>name</em> is the thread name. By default, a unique name is constructed of
the form "Thread-N" where N is a small decimal number.</p>
<p><em>args</em> is a list or tuple of arguments for the target invocation. Defaults to ().</p>
<p><em>kwargs</em> is a dictionary of keyword arguments for the target
invocation. Defaults to {}.</p>
<p>If a subclass overrides the constructor, it must make sure to invoke
the base class constructor (Thread.<strong>init</strong>()) before doing anything
else to the thread.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Calculator(threading.Thread):
    def __init__(self, meth, diagram, args, kwargs):
        self.meth, self.diagram, self.args, self.kwargs = meth, diagram, args, kwargs
        self.result = self.exception = None
        super().__init__(daemon=True)

    def run(self):
        try:
            self.result = self.meth(self.diagram, *self.args, **self.kwargs)
        except Exception as err:
            self.exception = err

    def get(self):
        self.join()
        if self.exception is not None:
            raise self.exception
        return self.result</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>threading.Thread</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="laueimproc.opti.parallel.Calculator.get"><code class="name flex">
<span>def <span class="ident">get</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get(self):
    self.join()
    if self.exception is not None:
        raise self.exception
    return self.result</code></pre>
</details>
</dd>
<dt id="laueimproc.opti.parallel.Calculator.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method representing the thread's activity.</p>
<p>You may override this method in a subclass. The standard run() method
invokes the callable object passed to the object's constructor as the
target argument, if any, with sequential and keyword arguments taken
from the args and kwargs arguments, respectively.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self):
    try:
        self.result = self.meth(self.diagram, *self.args, **self.kwargs)
    except Exception as err:
        self.exception = err</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="laueimproc.opti.parallel.ThreadManager"><code class="flex name class">
<span>class <span class="ident">ThreadManager</span></span>
</code></dt>
<dd>
<div class="desc"><p>Excecute several functions in parallel threads.</p>
<p>This constructor should always be called with keyword arguments. Arguments are:</p>
<p><em>group</em> should be None; reserved for future extension when a ThreadGroup
class is implemented.</p>
<p><em>target</em> is the callable object to be invoked by the run()
method. Defaults to None, meaning nothing is called.</p>
<p><em>name</em> is the thread name. By default, a unique name is constructed of
the form "Thread-N" where N is a small decimal number.</p>
<p><em>args</em> is a list or tuple of arguments for the target invocation. Defaults to ().</p>
<p><em>kwargs</em> is a dictionary of keyword arguments for the target
invocation. Defaults to {}.</p>
<p>If a subclass overrides the constructor, it must make sure to invoke
the base class constructor (Thread.<strong>init</strong>()) before doing anything
else to the thread.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ThreadManager(threading.Thread, metaclass=MetaSingleton):
    &#34;&#34;&#34;Excecute several functions in parallel threads.&#34;&#34;&#34;

    def __init__(self):
        self.jobs = {}  # each signature, associate the thread
        self.lock = threading.Lock()
        self.submit_event = queue.Queue(maxsize=1)  # faor passive waiting base on event
        super().__init__(daemon=True)  # daemon has to be true to allow to exit python
        self.start()

    def run(self):
        &#34;&#34;&#34;Asynchrone control loop.&#34;&#34;&#34;
        while True:
            # starts waiting threads
            with self.lock:
                running = [job for job in self.jobs.values() if job.is_alive()]
                if nbr_to_append := max(0, 3*CPU_AVAILABLE//2-len(running)):
                    for job in self.jobs.values():
                        if not job._started.is_set():  # pylint: disable=W0212
                            job.start()
                            if (nbr_to_append := nbr_to_append-1) == 0:
                                break

            # transfere terminated result thread in cache
            with self.lock:
                finish = {
                    signature: job for signature, job in self.jobs.items()
                    if job._started.is_set() and not job.is_alive() # pylint: disable=W0212
                }
                for signature in finish:
                    del self.jobs[signature]
            for signature, job in finish.items():
                with job.diagram._cache_lock:  # pylint: disable=W0212
                    try:
                        job.diagram._cache[signature] = job.get()  # pylint: disable=W0212
                    except Exception as err:  # pylint: disable=W0718
                        logging.error(err)

            # wait to free up resources
            job = running.pop(0) if running else None
            if job is not None:
                job.join()  # passive waiting
            else:
                try:
                    self.submit_event.get(timeout=0.5)
                except queue.Empty:  # beter than a short time.sleep active waiting
                    pass

    def submit_job(self, meth, diagram, args, kwargs, signature):
        if not self.is_alive():
            raise RuntimeError(&#34;the thread manager is dead&#34;)
        with self.lock:
            if signature not in self.jobs:
                self.jobs[signature] = Calculator(meth, diagram, args, kwargs)
            job = self.jobs[signature]
        try:
            self.submit_event.put_nowait(None)  # just for trigger main thread
        except queue.Full:
            pass
        return job

    def pop(self, meth, diagram, args, kwargs, signature):
        job = self.submit_job(meth, diagram, args, kwargs, signature)
        with self.lock:
            if not job._started.is_set():
                job.start()
        # return job.get()  # unreferenced by `run` thread
        res = job.get()
        with self.lock:  # delete all references
            if signature in self.jobs:
                del self.jobs[signature]
        with diagram._cache_lock:
            if signature in diagram._cache:
                del diagram._cache[signature]
        return res</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>threading.Thread</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="laueimproc.opti.parallel.ThreadManager.instances"><code class="name">var <span class="ident">instances</span> : dict[type, object]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="laueimproc.opti.parallel.ThreadManager.pop"><code class="name flex">
<span>def <span class="ident">pop</span></span>(<span>self, meth, diagram, args, kwargs, signature)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pop(self, meth, diagram, args, kwargs, signature):
    job = self.submit_job(meth, diagram, args, kwargs, signature)
    with self.lock:
        if not job._started.is_set():
            job.start()
    # return job.get()  # unreferenced by `run` thread
    res = job.get()
    with self.lock:  # delete all references
        if signature in self.jobs:
            del self.jobs[signature]
    with diagram._cache_lock:
        if signature in diagram._cache:
            del diagram._cache[signature]
    return res</code></pre>
</details>
</dd>
<dt id="laueimproc.opti.parallel.ThreadManager.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Asynchrone control loop.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self):
    &#34;&#34;&#34;Asynchrone control loop.&#34;&#34;&#34;
    while True:
        # starts waiting threads
        with self.lock:
            running = [job for job in self.jobs.values() if job.is_alive()]
            if nbr_to_append := max(0, 3*CPU_AVAILABLE//2-len(running)):
                for job in self.jobs.values():
                    if not job._started.is_set():  # pylint: disable=W0212
                        job.start()
                        if (nbr_to_append := nbr_to_append-1) == 0:
                            break

        # transfere terminated result thread in cache
        with self.lock:
            finish = {
                signature: job for signature, job in self.jobs.items()
                if job._started.is_set() and not job.is_alive() # pylint: disable=W0212
            }
            for signature in finish:
                del self.jobs[signature]
        for signature, job in finish.items():
            with job.diagram._cache_lock:  # pylint: disable=W0212
                try:
                    job.diagram._cache[signature] = job.get()  # pylint: disable=W0212
                except Exception as err:  # pylint: disable=W0718
                    logging.error(err)

        # wait to free up resources
        job = running.pop(0) if running else None
        if job is not None:
            job.join()  # passive waiting
        else:
            try:
                self.submit_event.get(timeout=0.5)
            except queue.Empty:  # beter than a short time.sleep active waiting
                pass</code></pre>
</details>
</dd>
<dt id="laueimproc.opti.parallel.ThreadManager.submit_job"><code class="name flex">
<span>def <span class="ident">submit_job</span></span>(<span>self, meth, diagram, args, kwargs, signature)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def submit_job(self, meth, diagram, args, kwargs, signature):
    if not self.is_alive():
        raise RuntimeError(&#34;the thread manager is dead&#34;)
    with self.lock:
        if signature not in self.jobs:
            self.jobs[signature] = Calculator(meth, diagram, args, kwargs)
        job = self.jobs[signature]
    try:
        self.submit_event.put_nowait(None)  # just for trigger main thread
    except queue.Full:
        pass
    return job</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="laueimproc.opti" href="index.html">laueimproc.opti</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="laueimproc.opti.parallel.auto_parallel" href="#laueimproc.opti.parallel.auto_parallel">auto_parallel</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="laueimproc.opti.parallel.Calculator" href="#laueimproc.opti.parallel.Calculator">Calculator</a></code></h4>
<ul class="">
<li><code><a title="laueimproc.opti.parallel.Calculator.get" href="#laueimproc.opti.parallel.Calculator.get">get</a></code></li>
<li><code><a title="laueimproc.opti.parallel.Calculator.run" href="#laueimproc.opti.parallel.Calculator.run">run</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="laueimproc.opti.parallel.ThreadManager" href="#laueimproc.opti.parallel.ThreadManager">ThreadManager</a></code></h4>
<ul class="">
<li><code><a title="laueimproc.opti.parallel.ThreadManager.instances" href="#laueimproc.opti.parallel.ThreadManager.instances">instances</a></code></li>
<li><code><a title="laueimproc.opti.parallel.ThreadManager.pop" href="#laueimproc.opti.parallel.ThreadManager.pop">pop</a></code></li>
<li><code><a title="laueimproc.opti.parallel.ThreadManager.run" href="#laueimproc.opti.parallel.ThreadManager.run">run</a></code></li>
<li><code><a title="laueimproc.opti.parallel.ThreadManager.submit_job" href="#laueimproc.opti.parallel.ThreadManager.submit_job">submit_job</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>